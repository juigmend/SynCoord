{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50eb0a68-a1d2-4361-8403-87d0f34d921b",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "*******************************************************************************************\n",
    "\n",
    "### Pose Tracking in Video Files, Pre-processing, and Audio Extraction\n",
    "\n",
    "##### 5 April 2025\n",
    "\n",
    "##### Juan Ignacio Mendoza Garay\n",
    "\n",
    "*******************************************************************************************\n",
    "\n",
    "</center>\n",
    "\n",
    "##### INFORMATION:\n",
    "\n",
    "* This program extracts one point of the human body (in this demonstration the nose), for every tracked person in the picture. A video file is produced with superimposed skeletons of tracked pose. Then, extraneous data is removed, missing data is interpolated, and tabular data is arranged. The resulting table has columns {p1_x,p1_y,p2_x,p2_y,...} where p is a tracked person from left to right, and {x,y} are horizontal and vertical coordinates of the point. Also, the audio from the video is extracted and it is added to the video of tracked pose.\n",
    "\n",
    "* Tested using:\n",
    "    * Python 3.11\n",
    "    * Windows 11\n",
    "    * Intel 64-bit CPU\n",
    ">\n",
    "* Dependencies:\n",
    "    * AlphaPose fork: https://github.com/juigmend/AlphaPose \\\n",
    "      Take note of the path of the folder where it is installed or copied to, because it is required when calling it.\n",
    "    * cython_bbox:\n",
    "        1) install Desktop Development with C++ from the Visual Studio Installer\n",
    "        2) type to command prompt: \\\n",
    "           set DISTUTILS_USE_SDK=1\n",
    "        3) install cython_bbox (e.g., using pip, conda, or other method)\n",
    "    * ffmpeg with path added to the system\n",
    "    * Other packages might be prompted for installation.\n",
    ">\n",
    "* Instructions:\n",
    "\n",
    "    Edit the values indicated with an arrow like this: <---\n",
    "\n",
    "* To improve the quality of tracking these can be tried:\n",
    "\n",
    "    *   use video with higher resolution if available\n",
    "    *   change parameters in detector/yolo_cfg.py, start by increasing INP_DIM\n",
    "    *   use another detector (e.g., yolox-x, yolox-l)\n",
    "    *   use another pretrained model\n",
    "    *   see documentation: https://github.com/MVIG-SJTU/AlphaPose/tree/master/docs\n",
    "\n",
    "*******************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbf0370-48b4-4ba3-8c67-7f916ddbd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as sys_path\n",
    "from os import chdir as os_chdir\n",
    "\n",
    "sys_path.append(r\"..\\src\")\n",
    "import syncoord as sc\n",
    "\n",
    "os_chdir(r\"..\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1124ac-3c44-4c34-acde-cf789f149959",
   "metadata": {},
   "source": [
    "***\n",
    "### Set paths and parameters\n",
    "These folders should exist before running the program. They will not be created automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af9c84a-9af7-4e7d-a6a4-88b4d4df99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = r\"string_quartet\"                      # <--- project folder\n",
    "video_in_path = project_folder+r\"\\input_video\"          # <--- input video files\n",
    "\n",
    "# Paths for resulting files:\n",
    "pose_tracking_path = project_folder + r'\\pose_tracking' # <---\n",
    "video_out_path = pose_tracking_path+r'\\video'           # <--- video with superimposed skeletons\n",
    "json_path = pose_tracking_path+r'\\tracking'             # <--- tracking (json format)\n",
    "prep_path = pose_tracking_path + r'\\preprocessed'       # <--- pre-processed data (parquet format)\n",
    "figs_path = pose_tracking_path + r'\\figures'            # <--- raw and pre-processed data figures\n",
    "\n",
    "AlphaPose_path = r\"C:\\MyTemp\\AlphaPose\"                 # <--- AlphaPose code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de9099-0e0d-4fa7-ac23-ad0c70a76c41",
   "metadata": {},
   "source": [
    "***\n",
    "### Video Tracking with AlphaPose\n",
    ">\n",
    "#### Process one video file, or video files in a folder\n",
    "This function detects and track pose; extracts audio fro the input video; produces video with superimposed skeletons, with and without audio. First check the values of parameters in \n",
    "AlphaPose\\detector\\yolo_cfg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535fe84-51fd-430b-9d38-98e9be7d63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrack_kwargs = {\n",
    "                 'video_out_path':video_out_path,\n",
    "                 'trim_range':[0,'end'],          # <--- trim range (seconds), scalars or 'end'\n",
    "                 'log_path': pose_tracking_path,  # <--- path for log text file\n",
    "                 'skip_done': False,              # <--- skip if resulting json file exists\n",
    "                 'suffix': '',                    # <--- label for file names\n",
    "                }\n",
    "sc.video.posetrack( video_in_path, json_path, AlphaPose_path, **ptrack_kwargs )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb51075-f40d-40bc-b8e6-60326eae7237",
   "metadata": {},
   "source": [
    ">\n",
    "#### Parameter-grid testing\n",
    "This function calls syncoord.video.posetrack, \n",
    "and it will dynamically edit the file AlphaPose\\detector\\yolo_cfg.py \\\n",
    "Consider making a backup copy of the file before using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b8eac-6286-4688-b350-ac6be5b49cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(sc.video)\n",
    "\n",
    "# Arguments passed to syncoord.video.posetrack:\n",
    "ptest_kwargs = {\n",
    "                 'video_out_path':video_out_path,\n",
    "                 'trim_range':[0,5],              # <---\n",
    "                 'log_path': pose_tracking_path,  # <---\n",
    "                 'skip_done': True,               # <---\n",
    "                 'suffix': '_gridtest',           # <---\n",
    "                }\n",
    "\n",
    "# Arguments specific to this function:\n",
    "test_par = {}\n",
    "test_par['idim'] = [640,768,1024] # <--- multiple of 32 (original = 608, more = better detection)\n",
    "test_par['thre'] = [0.6]          # <--- threshold (original = 0.6, fast = 0.45)\n",
    "test_par['conf'] = [0.1]          # <--- confidence (original = 0.1, fast = 0.5)\n",
    "\n",
    "sc.video.posetest( video_in_path, json_path, AlphaPose_path, test_par, **ptest_kwargs )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42d49b-5a5e-4b90-bd11-e99b7d89560b",
   "metadata": {},
   "source": [
    "***\n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859a30b-c62f-40f4-ae66-ece41b3e40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save pre-processing results:\n",
    "savepaths = {\n",
    "             'parquet':prep_path,      # <--- preprocessed data files (parquet format)\n",
    "             'rawfig': figs_path,      # <--- raw data visualisations\n",
    "             'prepfig': figs_path,     # <--- preprocessed data visualisatons\n",
    "             'log': pose_tracking_path # <--- log text file\n",
    "            }\n",
    "prepargs = {'skip_done':True} # <--- skip if resulting json file exists\n",
    "\n",
    "sc.video.poseprep(json_path,savepaths,**prepargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
